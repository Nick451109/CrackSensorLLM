python3.10 -m venv .venv
source .venv/bin/activate

pip install --upgrade pip
pip install --index-url https://download.pytorch.org/whl/cu121   torch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2
pip install "accelerate>=0.26.0"
pip install openai
pip install matplotlib
pip install statsmodels
pip install sentencepiece
pip install protobuf
pip install google
pip install protobuf
pip install google
pip uninstall -y flash-attn
pip install flash-attn==2.5.8 --no-build-isolation

-------probar comando unico -----
pip install --upgrade pip setuptools wheel && \
pip install --index-url https://download.pytorch.org/whl/cu121 \
  torch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 && \
pip install \
  "accelerate>=0.26.0" \
  matplotlib \
  statsmodels \
  sentencepiece \
  protobuf \
  openai && \
pip uninstall -y flash-attn && \
pip install flash-attn==2.5.8 --no-build-isolation
-----------------------------------------

---- Crear directorios ------
data/, whole_data/, outputs/
-----------------------------

-- (requirements.txt) comentar la linea "flash_attn"

pip install -r requirements.txt

-- Descargar dataset 

-- correr notebooks1 y 2 -----

export PYTHONPATH=$(pwd)
echo $PYTHONPATH

torchrun --nproc_per_node=1 sensorllm/train/train_mem.py \
  --model_name_or_path TinyLlama/TinyLlama-1.1B-Chat-v1.0 \
  --pt_encoder_backbone_ckpt amazon/chronos-t5-large \
  --dataset mhealth \
  --data_path data/train/mhealth_train_data_stage1.pkl \
  --eval_data_path data/test/mhealth_test_data_stage1.pkl \
  --qa_path data/train/mhealth_train_qa_stage1.json \
  --eval_qa_path data/test/mhealth_test_qa_stage1.json \
  --output_dir outputs/stage1_mhealth \
  --num_train_epochs 1 \
  --per_device_train_batch_size 1 \
  --per_device_eval_batch_size 1
